|description| |
|---|---|
|dir-name|Debezium|
|dir-name-en|Debezium|

# Debeziumを使用してOceanBaseに接続し、データを取得する

Debeziumは、データベースの変更をモニタリングし、データ変更イベントを捉えて、イベントストリーム形式でエクスポートし、さまざまなコンシューマに配信するためのオープンソースの分散プラットフォームです。DebeziumはApache Kafkaを基盤としており、複数のデータベースシステムをサポートします。

## 前提条件

Debeziumを使用する前に、oblogproxyがインストールされていることを確認してください。

## 使用例

本記事では、Dockerを使用してDebeziumをOceanBaseに接続し、データを取得する方法を簡単に示します。このデプロイ方法は、本番環境での直接利用には適していません。以下の手順に従って操作します：

1. Zookeeperを起動する

    ```shell
    docker run -it -d --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 quay.io/debezium/zookeeper:2.4
    ```

2. Kafkaを起動する

    ```shell
    docker run -it -d --name kafka -p 9092:9092 --link zookeeper:zookeeper quay.io/debezium/kafka:2.4
    ```

3. Kafka Connectサービスを起動します。このサービスは、Debezium MySQLコネクタを管理するためのREST APIを公開しています。

    ```shell
    docker run -it -d --name connect -p 8083:8083 -e GROUP_ID=1 -e CONFIG_STORAGE_TOPIC=my_connect_configs -e OFFSET_STORAGE_TOPIC=my_connect_offsets -e STATUS_STORAGE_TOPIC=my_connect_statuses --link kafka:kafka  quay.io/debezium/connect:2.4
    ```

4. 新たに `payload.json` ファイルを作成し、以下の設定例を記述します。

   ```json
      {
      "name": "inventory-connector",
      "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "tasks.max": "1",
        "database.hostname": "xxxx.cn-hangzhou.oceanbase.aliyuncs.com",
        "database.port": "3306",
        "database.user": "root",
        "database.password": "xxxx",
        "database.server.id": "1",
        "topic.prefix": "observer1",
        "database.include.list": "debe",
        "table.include.list":"debe.earthquake",
        "schema.history.internal.store.only.captured.tables.ddl":true,
        "schema.history.internal.skip.unparseable.ddl":true,
        "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
        "schema.history.internal.kafka.topic": "schema-changes.inventory",
        "snapshot.locking.mode": "none"
      }
    }
   ```

<main id="notice" type='notice'>
<h4>注意</h4>
<p><ol>
  <li>MySQLコネクタはOceanBaseの <code>PURGE TABLE</code> などの構文を認識できません。<code>schema.history.internal.skip.unparseable.ddl</code> オプションを設定することで回避できます。</li>
  <li>OceanBase独自の仮想テーブルとビューを同期させたくない場合は、<code>table.include.listまたはtable.exclude.list</code> パラメータを使用してフィルタリングできます。</li>
  <li>curlコマンドを使用して、Kafka ConnectサービスのAPIに対して /connectorsリソースへのPOSTリクエストを送信し、上記の新規コネクタのJSONドキュメントを添付します。<br><code>
cat payload.json | tr -d "\n" | curl -X POST -H "Content-Type: application/json" -d @- localhost:8083/connectors/</code></li>
<li>コネクタを登録すると、Kafka Connectコンテナで大量のログが出力されます。これらの出力から、コネクタがOceanBaseのBinlogの作成から読み込みを開始するまでのプロセスを観察できます。
<br><code>docker run -it --rm --name watcher --link zookeeper:zookeeper --link kafka:kafka quay.io/debezium/kafka:2.4 watch-topic -a -k observer1.debe.earthquake</code></li>
</ol>
</p>
</main>
