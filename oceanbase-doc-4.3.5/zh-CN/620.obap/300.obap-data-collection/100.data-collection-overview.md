# 数据采集概述

数据采集是数据管理的基础环节，指从数据源（如数据库、日志文件等）获取数据，并传输到 OceanBase 数据库的过程。根据数据采集的触发机制和数据范围，可分为两大核心类型：数据订阅（增量迁移）和文件导入数据。

## 数据订阅

**数据订阅（Data Subscription）** ，也就是**增量迁移**，数据订阅是一种持续捕获数据源增量变更的技术，核心是通过变更数据捕获（CDC, Change Data Capture）实时或准实时地将数据变化（新增、更新、删除）传输到目标系统。其核心目标是：

+ **低延迟同步**：确保目标系统与源系统数据一致。
+ **资源高效**：仅传输差异数据，而非全量数据。
+ **灵活扩展**：支持多目标系统（如数据仓库、分析平台）。

**典型应用场景**：

+ 实时分析（如订单系统到 BI 平台的实时数据同步）。
+ 灾备与多活架构（如数据库到灾备集群的增量复制）。
+ 跨系统数据治理（如将 MySQL 数据订阅到 Hive 进行离线分析）。

更多详细信息，请参见[数据订阅概述](200.data-subscription-overview.md)。

## 文件导入数据

OceanBase 数据库提供多种灵活的数据入库方式，可以将多种数据源的数据导入到数据库中。不同的导入方式适用于不同的场景，可以根据数据源类型、业务场景，选择合适的导数工具进行数据入库。随着场景的复杂多变，多种导入方式可以配合使用。

在数据入库时，除了考虑数据源、数据文件格式也会考虑导数工具的支持情况。当业务场景已经明确数据源、数据文件格式时，需要从数据源出发，并结合导数工具来考虑导数方案的设计；当业务有熟练使用的导数工具时，需要考虑工具的支持情况，结合业务场景考虑导数的可能性。

### 主要导入方式

+ **LOAD DATA 语法**：适用于大规模数据导入，支持 CSV、ORC、Parquet 等格式
+ **OBLoader**：OceanBase 官方提供的数据导入工具，支持多种文件格式的批量导入
+ **外表**：适用于数据湖分析场景，无需将数据实际导入数据库
+ **INSERT SQL**：适用于少量数据的写入操作
+ **第三方工具**：如 OMS、DataX、Flink、Canal 等，支持不同场景的数据导入

### 支持的数据源

+ **文件系统**：本地文件、对象存储、HDFS 等
+ **数据库**：MySQL、Oracle、PostgreSQL 等关系型数据库
+ **大数据平台**：MaxCompute、StarRocks、Doris、HBase 等
+ **实时数据流**：Kafka、Flink 等流式数据

更多详细信息，请参见[导入数据概述](300.obap-import-data/10.obap-import-overview.md)。
