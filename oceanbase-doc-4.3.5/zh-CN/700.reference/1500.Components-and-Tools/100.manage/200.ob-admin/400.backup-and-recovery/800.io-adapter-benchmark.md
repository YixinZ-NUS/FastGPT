# io_adapter_benchmark

io_adapter_benchmark 命令用于验证 OBServer 节点到备份介质的读写性能。本文主要介绍 io_adapter_benchmark 命令的几种用法。

<main id="notice" type='explain'>
  <h4>说明</h4>
  <ul>
  <li><p>执行 ob_admin 命令前，可以执行 <code>export OB_ADMIN_LOG_DIR=&lt;your_log_path&gt;</code> 指定 ob_admin 执行日志存放目录。<code>your_log_path</code> 需根据实际情况进行替换，并保证对应目录存在。</p></li>
  <li><p>对于 OceanBase 数据库 V4.3.5 版本，<code>io_adapter_benchmark</code> 命令自 V4.3.5 BP3 版本更新，之前版本的命令介绍可参见 <a href="https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001576763">io_adapter_benchmark</a>。</p></li>
  </ul>
</main>

## 命令介绍

您可在 io_adapter_benchmark 命令中配置 `-h` 输出命令的使用介绍。

```shell
./ob_admin io_adapter_benchmark -h
```

输出如下：

```shell
Usage: io_adapter_benchmark command [command args] [options]
commands:
        -h, --help                    display this message.
options:
        -d, --file-path-prefix        required, absolute file path with file prefix
        -s, --storage-info            required, oss/cos should provide storage info
        -p, --type                    specifies the test type, the values can be auto-run, write, append, multi, read, del, is_exist, read_user_provided
        -t, --thread-num              thread num
        -r, --max-task-run-times      max task run times for each thread, default is 10
        -l, --time-limit              time limit in second
        -o, --object-size             object size, default is 2097152, 2M
        -n, --object-num              object num, default is 10
        -f, --fragment-size           for read operations, 'fragment-size' denotes the expected size of data to be read, while for append/multipart write tasks, it specifies the size of each individual pwrite operation.
        --write-size                  specifies the object size in put task when type is auto-run, default is 2097152, 2M
        --append-size                 specifies the object size in append-write task when type is auto-run, default is 67108864, 64M
        --append-fragment-size        specifies the fragment size in append-write task when type is auto-run, default is 0, denote each time random
        --multi-size                  specifies the object size in multi-write task when type is auto-run, default is 67108864, 64M
        --multi-fragment-size         specifies the fragment size in multi-write task when type is auto-run, default is 2097152, 2M
        -j, --is-adaptive             use adative interface
        -c, --clean-after-execution   clean after execution
        -e, --s3_url_encode_type      set S3 protocol url encode type
        -i, --sts_credential          set sts credential
        -a                            enable obdal
samples:
  test nfs device:
        ob_admin io_adapter_benchmark -d'file:///home/admin/backup_info'
  test object device:
        ob_admin io_adapter_benchmark -d'oss://home/admin/backup_info' -s'host=xxx.com&access_id=111&access_key=222'
        ob_admin io_adapter_benchmark -d's3://home/admin/backup_info' -s'host=xxx.com&access_id=111&access_key=222&region=333'  -e'compliantRfc3986Encoding'
        ob_admin io_adapter_benchmark -d'oss://home/admin/backup_info' -s'host=xxx.com&role_arn=xxx'-i'sts_url=xxx&sts_ak=aaa&sts_sk=bbb'
```

各个选项的介绍如下：

| 选项  | 说明   |
|------|--------|
| -d/--file-path-prefix  | 指定测试目录，需要指定为带文件前缀的绝对文件路径。 |
| -s/--storage-info  | 指定对象存储校验信息。  |
| -p/--type  | 指定测试类型，可取值为 `auto-run`、`write`、`append`、`multi`、`read`、`del`、`is_exist`、`read_user_provided`，各个取值的具体介绍可参见下文取值介绍。  |
| -t/--thread-num  | 设置并发线程数。 |
| -r/--max-task-run-times  |  设置单个线程执行任务的次数，默认值为 10。  |
| -l/--time-limit  |  设置总的运行时间限制。  |
| -o/--object-size  |  设置对象大小，默认为 2097152 字节，即 2 MB。 |
| -n/--object-num  |  设置对象数量，默认为 10。  |
| -f/--fragment-size  |  对于 read 操作，该选项指定单次读取的数据大小；对于 append/multipart write 操作，该选项指定单次写入的数据大小。  |
| --write-size  | `-p`/`--type` 指定为 `auto-run` 时使用，指定 put 任务中的对象大小，默认为 2097152 字节，即 2 MB。 |
| --append-size  | `-p`/`--type` 指定为 `auto-run` 时使用，指定追加写入任务中的对象大小，默认为 67108864 字节，即 64 MB。 |
| --append-fragment-size  | `-p`/`--type` 指定为 `auto-run` 时使用，指定追加写入任务中的片段大小，默认值为 `0`，表示每次随机。  |
| --multi-size  | `-p`/`--type` 指定为 `auto-run` 时使用，指定 multipart 写文件的对象大小，默认为 67108864 字节，即 64 MB。 |
| --multi-fragment-size  | `-p`/`--type` 指定为 `auto-run` 时使用，指定追加写入任务中的片段大小，默认值为 `0`，表示每次随机。  |
| -j/--is-adaptive  | 设置是否使用自适应界面，无需传值，命令执行时携带该选项即表示使用自使用界面。  |
| -c/--clean-after-execution  |  设置是否在任务完成后清理目录，无需传值，命令执行时携带该选项即表示在任务完成后清理目录。 |
| -e/--s3_url_encode_type  | 设置 S3 协议 URL 编码类型。 |
| -i/--sts_credential  | 设置 STS（Security Token Service，临时安全令牌服务） 凭据。  |
| -a  | 设置是否启用 obdal，obdal 为基于 opendal 开发的对象存储统一框架。无需传值，命令执行时携带该选项即表示启用 obdal。  |

`-p`/`--type` 选项支持的取值介绍如下：

| 取值  | 含义   |
|-------|--------|
| `auto-run` | 一键执行模式，会依次执行如下测试：<ul><li>普通写文件，文件大小通过 <code>--write-size</code> 指定，默认为 2MB。</li><li>读普通文件，单次读取数据大小为 16K。</li><li>读普通文件，单次读取数据大小为 2MB。</li><li>追加写文件，大小通过 <code>--append-size</code> 指定，默认为 64MB。每次追加写 <code>--append-fragment-size</code> 大小的文件，若未指定，则每次追加写入随机大小的片段。</li><li>读追加写文件，单次写入数据大小为 2MB。</li><li>multipart 写文件，大小通过 <code>--multi-size</code> 指定，默认为 64MB，每次追加写 <code>--multi-fragment-size</code> 大小的文件，默认为 2MB。</li><li>读 multipart 写入的文件，单次读取数据大小为 2MB。</li></ul>  |
| `write` | 表示写普通文件，每个线程会在一个单独的目录下写入。  |
| `append`  | 表示追加写文件。  |
| `multi`  | 表示分片上传。  |
| `read`  | 表示读取文件，必须先写入数据才可以执行 read 任务。  |
| `del`  | 表示删除数据，每个线程删除一个单独目录下的数据，设置的线程数需等于写入时设置的线程数。  |
| `is_exist` | 表示并发读取指定路径的元信息。  |
| `read_user_provided`  | 表示并发读取指定文件。  |

## 示例

### 一键执行

```shell
./ob_admin io_adapter_benchmark -d'oss://oss_bucket/test_path' -s'host=xxx.com&access_id=xxx&access_key=xxx'
```

此处只是简单示例，您可通过 `-t` 选项指定并发度，`-r` 选项指定每个线程执行的次数，`-n` 选项指定读取的文件个数（不得大于 `-r` 选项），这些选项配置后可作用于一键执行中的所有测试。

命令执行后输出如下：

```shell
succ to open, filename=/home/admin/log/ob_admin_log/ob_admin.log, fd=6, wf_fd=2
succ to open, filename=/home/admin/log/ob_admin_log/ob_admin_rs.log, fd=7, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:-1, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"NORMAL_WRITE"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/write
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|1.217186 s
|               Total user time|0.325087 s
|             Total system time|0.054429 s
|      CPU usage for 100MB/s BW|47.439500% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|32.862685
|                Per Thread QPS|8.215671
|                      Total BW|65.725370 MB/s
|                 Per Thread BW|16.431342 MB/s
|             Total Op Time Map|total_entry=40, min_ms=63, th_50_ms=81, th_90_ms=119, th_99_ms=181, th_999_ms=181, max_ms=197
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:16384, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"READ"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/write
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|0.360966 s
|               Total user time|0.024254 s
|             Total system time|0.005977 s
|      CPU usage for 100MB/s BW|483.696000% per 100MB/s
|        Total throughput bytes|655360
|                     Total QPS|110.813761
|                Per Thread QPS|27.703440
|                      Total BW|1.731465 MB/s
|                 Per Thread BW|0.432866 MB/s
|             Total Op Time Map|total_entry=40, min_ms=17, th_50_ms=28, th_90_ms=37, th_99_ms=41, th_999_ms=41, max_ms=48
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:2097152, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"READ"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/write
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|0.427612 s
|               Total user time|0.074748 s
|             Total system time|0.080815 s
|      CPU usage for 100MB/s BW|19.445375% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|93.542744
|                Per Thread QPS|23.385686
|                      Total BW|187.085489 MB/s
|                 Per Thread BW|46.771372 MB/s
|             Total Op Time Map|total_entry=40, min_ms=20, th_50_ms=39, th_90_ms=48, th_99_ms=67, th_999_ms=67, max_ms=83
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:67108864, obj_num:10, fragment_size:-1, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"APPEND_WRITE"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/append
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|26.289182 s
|               Total user time|1.519549 s
|             Total system time|1.215221 s
|      CPU usage for 100MB/s BW|10.682695% per 100MB/s
|        Total throughput bytes|2684354560
|                     Total QPS|1.521538
|                Per Thread QPS|0.380385
|                      Total BW|97.378458 MB/s
|                 Per Thread BW|24.344614 MB/s
|             Total Op Time Map|total_entry=40, min_ms=1831, th_50_ms=2462, th_90_ms=2822, th_99_ms=3008, th_999_ms=3008, max_ms=3576
|                 Open Time Map|total_entry=40, min_ms=0, th_50_ms=0, th_90_ms=0, th_99_ms=0, th_999_ms=0, max_ms=0
|             Close Op Time Map|total_entry=40, min_ms=0, th_50_ms=0, th_90_ms=0, th_99_ms=0, th_999_ms=0, max_ms=0
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:67108864, obj_num:10, fragment_size:2097152, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"READ"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/append
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|2.459746 s
|               Total user time|0.112226 s
|             Total system time|0.119849 s
|      CPU usage for 100MB/s BW|29.009375% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|16.261842
|                Per Thread QPS|4.065460
|                      Total BW|32.523683 MB/s
|                 Per Thread BW|8.130921 MB/s
|             Total Op Time Map|total_entry=40, min_ms=95, th_50_ms=215, th_90_ms=254, th_99_ms=280, th_999_ms=280, max_ms=338
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:67108864, obj_num:10, fragment_size:2097152, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"MULTIPART_WRITE"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/multi
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|18.631304 s
|               Total user time|1.902340 s
|             Total system time|1.163696 s
|      CPU usage for 100MB/s BW|11.976703% per 100MB/s
|        Total throughput bytes|2684354560
|                     Total QPS|2.146924
|                Per Thread QPS|0.536731
|                      Total BW|137.403158 MB/s
|                 Per Thread BW|34.350789 MB/s
|             Total Op Time Map|total_entry=40, min_ms=1754, th_50_ms=1856, th_90_ms=1921, th_99_ms=1969, th_999_ms=1969, max_ms=1984
|                 Open Time Map|total_entry=40, min_ms=15, th_50_ms=19, th_90_ms=27, th_99_ms=38, th_999_ms=38, max_ms=43
|             Close Op Time Map|total_entry=40, min_ms=46, th_50_ms=62, th_90_ms=85, th_99_ms=92, th_999_ms=92, max_ms=119
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:67108864, obj_num:10, fragment_size:2097152, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"READ"}
|                Task work path|oss://oss_bucket/test_path/test_io_device_2025-04-10-10:36:09/multi
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|0.573971 s
|               Total user time|0.060743 s
|             Total system time|0.069399 s
|      CPU usage for 100MB/s BW|16.267750% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|69.689932
|                Per Thread QPS|17.422483
|                      Total BW|139.379864 MB/s
|                 Per Thread BW|34.844966 MB/s
|             Total Op Time Map|total_entry=40, min_ms=36, th_50_ms=47, th_90_ms=73, th_99_ms=77, th_999_ms=77, max_ms=117
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
```

### 写普通文件

```shell
./ob_admin io_adapter_benchmark -d 'oss://oss_bucket/test_path' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -o 100 \  # 对象大小设置为 100 字节
                              -t 4   \  # 4 线程并行
                              -r 10  \  # 单个线程写入的对象数量上限为 10 个
                              -p 'write' \
                              -c  \
```

上述命令会在 `oss_bucket/test_path` 目录下执行写普通文件的性能测试。将通过四个线程（`-t 4` 指定）并发向该目录写入对象，每个对象大小为 100 字节（`-o 100` 指定），直到每个线程写入 10 个对象（`-r 10` 指定）后停止写入。测试完成后会清空目录（`-c` 指定）。

命令执行后输出如下：

```shell
succ to open, filename=/root/log/ob_admin.log, fd=5, wf_fd=2
succ to open, filename=/root/log/ob_admin_rs.log, fd=6, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:100, obj_num:10, fragment_size:2097152, is_adaptive:false, BenchmarkTaskTypeStr[type_]:"NORMAL_WRITE"}
|                Task work path|oss://oss_bucket/test_path
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|0.244780 s
|               Total user time|0.014648 s
|             Total system time|0.003975 s
|      CPU usage for 100MB/s BW|48819.077120% per 100MB/s
|        Total throughput bytes|4000
|                     Total QPS|163.412043
|                Per Thread QPS|40.853011
|                      Total BW|0.015584 MB/s
|                 Per Thread BW|0.003896 MB/s
|             Total Op Time Map|total_entry=40, min_ms=12, th_50_ms=16, th_90_ms=29, th_99_ms=77, th_999_ms=77, max_ms=78
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Ma
```

### 追加写文件

```shell
./ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -o 100 \  # 对象大小设置为 100 字节
                              -t 4   \  # 4 线程并行
                              -r 10  \  # 单个线程写入的对象数量上限为 10 个
                              -p 'append' \
                              -f 10  \ # 写入一个对象时，每次 append 10 字节，即 append 10 次后完成一个对象（此例中为 100 字节）的写入
```

命令执行后输出如下：

```shell
succ to open, filename=/tmp/ob_admin.log, fd=3, wf_fd=2
succ to open, filename=/tmp/ob_admin_rs.log, fd=4, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:2097152, obj_num:-1, fragment_size:1048576, is_adaptive:false, type:1}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|5.685847 s
|               Total user time|0.776306 s
|             Total system time|0.073172 s
|      CPU usage for 100MB/s BW|106.184750% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|7.035012
|                Per Thread QPS|1.758753
|                      Total BW|14.070023 MB/s
|                 Per Thread BW|3.517506 MB/s
|             Total Op Time Map|total_entry=40, min_ms=364, th_50_ms=419, th_90_ms=704, th_99_ms=754, th_999_ms=754, max_ms=963
|                 Open Time Map|total_entry=40, min_ms=0, th_50_ms=3, th_90_ms=3, th_99_ms=3, th_999_ms=3, max_ms=3
|             Close Op Time Map|total_entry=40, min_ms=103, th_50_ms=112, th_90_ms=123, th_99_ms=124, th_999_ms=124, max_ms=125
```

### 分片上传

```shell
./ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -o 100 \  # 对象大小设置为 100 字节
                              -t 4   \  # 4 线程并行
                              -r 10  \  # 单个线程写入的对象数量上限为 10 个
                              -p 'multi' \
                              -f 10  \  # 单次写入的大小为 10 字节，相当于一个对象（此例中为 100 字节）包含 10 次写入操作
```

对于目前对象存储的分片上传实现来说，每个 part 聚合到 8MB 后才会真正写入一个分片，即写入次数不等于 part 数。

命令执行后输出如下：

```shell
succ to open, filename=/tmp/ob_admin.log, fd=3, wf_fd=2
succ to open, filename=/tmp/ob_admin_rs.log, fd=4, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:10, time_limit_s:-1, obj_size:2097152, obj_num:-1, fragment_size:1048576, is_adaptive:false, type:2}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|40
|          Total execution time|7.135682 s
|               Total user time|0.765570 s
|             Total system time|0.095029 s
|      CPU usage for 100MB/s BW|107.574875% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|5.605631
|                Per Thread QPS|1.401408
|                      Total BW|11.211262 MB/s
|                 Per Thread BW|2.802815 MB/s
|             Total Op Time Map|total_entry=40, min_ms=314, th_50_ms=411, th_90_ms=762, th_99_ms=833, th_999_ms=833, max_ms=1002
|                 Open Time Map|total_entry=40, min_ms=43, th_50_ms=50, th_90_ms=57, th_99_ms=99, th_999_ms=99, max_ms=102
|             Close Op Time Map|total_entry=40, min_ms=269, th_50_ms=357, th_90_ms=708, th_99_ms=781, th_999_ms=781, max_ms=900
```

### 读取文件

```shell
ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -o 100  \  # 对象大小设置为 100 字节
                              -t 4    \  # 4 线程并行
                              -r 10   \  # 单个线程执行的 read 操作上限为 10 个
                              -p 'read' \
                              -f 10   \  # 单次 read 操作的读取数据大小，表示随机读取 10 字节数据
                                      \   # 如果需要读取完整对象，可以设置 -f'obj_size'
                              -j 1    \  # 如果备份目录是 S3/OBS 格式，需要设置 -j'1'
                              -n 10  \  # 数据写入时，单个线程写入的对象数为 10
```

执行如上命令时需注意，必须先写入数据才能执行读取任务，使用 `-n` 选项指定之前每个线程已写入的对象数（写入任务命令中 `-r` 对应数值），并行数（`-t`）不能大于写入数据时指定的并行数。

<main id="notice" type='explain'>
  <h4>说明</h4>
  <p>若已执行多个写入命令，以读取命令中 <code>-d</code> 指定的对应目录下最近的写入命令为准，即 <code>-n</code> 和 <code>-r</code> 都需要参照对应命令进行设置。</p>
</main>

命令执行后输出如下：

```shell
succ to open, filename=/tmp/ob_admin.log, fd=3, wf_fd=2
succ to open, filename=/tmp/ob_admin_rs.log, fd=4, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:20, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:1048576, is_adaptive:true, type:3}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|80
|          Total execution time|2.970364 s
|               Total user time|0.289431 s
|             Total system time|0.217354 s
|      CPU usage for 100MB/s BW|63.348125% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|26.932726
|                Per Thread QPS|6.733182
|                      Total BW|26.932726 MB/s
|                 Per Thread BW|6.733182 MB/s
|             Total Op Time Map|total_entry=80, min_ms=114, th_50_ms=132, th_90_ms=164, th_99_ms=356, th_999_ms=356, max_ms=389
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
```

### 删除数据

```shell
ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -t 4     \  # 4 线程并行
                              -p 'del' \
                              -j 1     \ # 如果备份目录是 S3/OBS 格式，需要设置 -j '1'
                              -r 10    \ # 必须等于写入时指定的写入数量
```

执行如上命令时需注意，每个线程删除一个单独目录下的数据，所以设置的线程数（`-t`）需要等于写入时设置的并行数。

<main id="notice" type='explain'>
  <h4>说明</h4>
  <p>若已执行多个写入命令，以读取命令中 <code>-d</code> 指定的对应目录下最近的写入命令为准，即 <code>-t</code> 和 <code>-r</code> 都需要参照对应命令进行设置。</p>
</main>

命令执行后输出如下：

```shell
succ to open, filename=/tmp/ob_admin.log, fd=3, wf_fd=2
succ to open, filename=/tmp/ob_admin_rs.log, fd=4, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:20, time_limit_s:-1, obj_size:-1, obj_num:-1, fragment_size:-1, is_adaptive:true, type:4}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|80
|          Total execution time|2.136603 s
|               Total user time|0.155563 s
|             Total system time|0.014127 s
|               Total CPU usage|7.942046%
|        Total throughput bytes|0
|                     Total QPS|37.442613
|                Per Thread QPS|9.360653
|                      Total BW|0.000000 MB/s
|                 Per Thread BW|0.000000 MB/s
|             Total Op Time Map|total_entry=80, min_ms=77, th_50_ms=94, th_90_ms=105, th_99_ms=159, th_999_ms=159, max_ms=166
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
```

### 并发读取指定路径元信息

```shell
ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -t 4     \  # 4 线程并行
                              -p 'is_exist'  \
                              -r 100   \  # 单线程读取 100 次
```

命令执行后输出如下：

```shell
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:100, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:-1, is_adaptive:false, type_str:"IS_EXIST"}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|400
|          Total execution time|8.711115 s
|               Total user time|0.122446 s
|             Total system time|0.034527 s
|               Total CPU usage|1.801985%
|        Total throughput bytes|0
|                     Total QPS|45.918347
|                Per Thread QPS|11.479587
|                      Total BW|0.000000 MB/s
|                 Per Thread BW|0.000000 MB/s
|             Total Op Time Map|total_entry=400, min_ms=33, th_50_ms=35, th_90_ms=41, th_99_ms=51, th_999_ms=147, max_ms=5074
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
```

### 并发读取指定文件

```shell
ob_admin io_adapter_benchmark -d 'oss://home/admin/backup_info' \
                              -s 'host=xxx.com&access_id=111&access_key=222' \
                              -t 4     \  # 4 线程并行
                              -p 'read_user_provided'
                              -r 100   \  # 单线程读取 100 次
                              -o 100   \  # 提示文件大小，必须小于等于文件真实大小
                              -f 50    \  # 单次读取操作大小，必须小于等于 -o 参数指定大小
```

命令执行后输出如下：

```shell
succ to open, filename=/tmp/ob_admin.log, fd=3, wf_fd=2
succ to open, filename=/tmp/ob_admin_rs.log, fd=4, wf_fd=2
------------------------------{Testing}------------------------------
|                   Task Config|{thread_num:4, max_task_runs:20, time_limit_s:-1, obj_size:2097152, obj_num:10, fragment_size:1048576, is_adaptive:true, type:3}
|                Task work path|oss://home/admin/backup_info
|                        Status|SUCCESS
|           Total operation num|80
|          Total execution time|2.970364 s
|               Total user time|0.289431 s
|             Total system time|0.217354 s
|      CPU usage for 100MB/s BW|63.348125% per 100MB/s
|        Total throughput bytes|83886080
|                     Total QPS|26.932726
|                Per Thread QPS|6.733182
|                      Total BW|26.932726 MB/s
|                 Per Thread BW|6.733182 MB/s
|             Total Op Time Map|total_entry=80, min_ms=114, th_50_ms=132, th_90_ms=164, th_99_ms=356, th_999_ms=356, max_ms=389
|                 Open Time Map|Empty Time Map
|             Close Op Time Map|Empty Time Map
```
