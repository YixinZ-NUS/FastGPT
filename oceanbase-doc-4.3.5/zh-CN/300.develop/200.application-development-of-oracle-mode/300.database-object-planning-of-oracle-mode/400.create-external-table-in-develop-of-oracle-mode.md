|description||
|---|---|
|keywords||
|dir-name||
|dir-name-en||
|tenant-type|Oracle Mode|

# 创建外表

本文将向您介绍如何使用 SQL 语句来创建外表，同时介绍创建外表的前提条件、外表简介和注意事项等，并提供一些示例。

## 外表简介

外表是指一个逻辑上的表对象，它对应的实际数据存储位置并不在数据库内部，而是存储于外部存储服务中。

更多外表的信息，请参见 [关于外表](../../../700.reference/300.database-object-management/200.manage-object-of-oracle-mode/100.manage-tables-of-oracle-mode/1000.manage-external-tables-of-oracle-mode/100.about-external-tables-of-oracle-mode.md)。

## 前提条件

在创建外表前，您需要确认以下事项：

* 您已部署 OceanBase 集群并且创建了 Oracle 模式租户。更多有关部署 OceanBase 集群的信息，请参见 [部署概述](../../../400.deploy/100.deploy-overview.md)。

* 您已连接到 OceanBase 数据库的 Oracle 租户。更多连接数据库的信息，请参见 [连接方式概述](../100.connect-to-oceanbase-database-of-oracle-mode/100.connection-methods-overview-of-oracle-mode.md)。

* 创建外表需要当前用户拥有 `CREATE TABLE` 权限。更多查看当前用户权限的相关操作信息，请参见 [查看用户权限](../../../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/300.permission-of-oracle-mode/600.view-user-permissions-of-oracle-mode.md)。如果不具备该权限，请联系管理员为您授权，有关用户授权的相关操作信息，请参见 [直接授予权限](../../../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/300.permission-of-oracle-mode/200.authority-of-oracle-mode.md)。

## 注意事项

* 外表只能执行查询操作，不能执行 DML 操作。

* 查询外表时，如果外表所访问的外部文件已删除，系统不会报错，会返回空行。

* 由于外表所访问的文件由外部存储系统进行管理，当外部存储不可用时，查询外表将会报错。

* 由于外部表的数据存储在外部数据源中，因此在查询时会涉及跨网络、文件系统等因素，可能会影响查询性能。因此，需要在创建外部表时选择合适的数据源和优化策略，以提高查询效率。

## 使用命令行创建外表

请使用 [CREATE EXTERNAL TABLE](../../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/900.sql-statement-of-oracle-mode/100.ddl-of-oracle-mode/1600.create-external-table-of-oracle-mode.md) 语句创建外表。

### 定义外表名

创建外表时，需要先为外表命名，为了避免混淆和歧义，建议在给外部表命名时使用特定的命名规则或前缀来区分普通表和外部表。例如，外表的名称后缀可以为 `_csv`。

示例如下：

创建一个有关学生信息的外表时，可以命名为 `students_csv`。

```sql
CREATE EXTERNAL TABLE students_csv external_options
```

<main id="notice" type='notice'>
  <h4>注意</h4>
  <p>因为外表的其他属性未添加，所以上面的 SQL 语句不能运行。</p>
</main>

### 定义列

外表的列不能定义约束，例如，`DEFAULT`、`NOT NULL`、`UNIQUE`、`CHECK`、`PRIMARY KEY`、`FOREIGN KEY` 等。

外表支持的列类型与普通表一致。OceanBase 数据库 Oracle 模式中支持的数据类型及详细介绍请参见 [内建数据类型概述](../../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/300.basic-elements-of-oracle-mode/100.built-in-data-types-of-oracle-mode/100.overview-of-built-in-data-types-of-oracle-mode.md)。

### 定义 LOCATION

`LOCATION` 选项用来指定外表文件存放的路径。通常外表的数据文件存放于单独一个目录中，文件夹中可以包含子目录，在创建表时，外表会自动收集该目录中的所有文件。

OceanBase 数据库支持以下两种路径格式：

* 本地 Location 格式：`LOCATION = '[file://] local_file_path'`

  <main id="notice" type='notice'>
  <h4>注意</h4>
  <p>对于使用本地 Location 格式的场景，需设置系统变量 <code>secure_file_priv</code> 配置可以访问的路径。更多信息，请参见 <a href="../../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>。</p>
  </main>

* 远程 Location 格式如下：

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>使用对象存储路径时，对象存储路径的各项参数由 <code>&</code> 符号进行分隔，请确保您输入的参数值中仅包含英文字母大小写、数字、<code>/-_$+=</code> 以及通配符。如果您输入了上述以外的其他字符，可能会导致设置失败。</p>
  </main>

  * `LOCATION = '{oss|S3}://$ACCESS_ID:$ACCESS_KEY@$HOST:s3_region/remote_file_path'` ，其中 `$ACCESS_ID`、`$ACCESS_KEY` 和 `$HOST` 为访问阿里云 OSS、AWS S3 以及兼容 S3 协议的对象存储所需配置的访问信息，`s3_region` 为使用 S3 时选择的区域信息，这些敏感的访问信息会以加密的方式存放在数据库的系统表中

  * 文件在 HDFS 上时，有以下格式：

    * 基于单节点 NameNode（NN）地址访问集群格式为：`LOCATION = hdfs://localhost:port/PATH`，其中 `localhost` 指的是 HDFS 的地址，`port` 指的是 HDFS 的端口号，`PATH` 指 HDFS 中的文件路径。

      * 带 kerberos 认证的格式为：`LOCATION = 'hdfs://localhost:port/user?principal=xxx&keytab=xxx&krb5conf=xxx&configs=xxx'`，其中：

        * `principal`：指登录认证用户。
        * `keytab`：指定用户认证的密钥文件路径。
        * `krb5conf`：指定用户使用 kerberos 环境的描述文件路径。
        * `configs`：指定额外的 HDFS 配置项，默认为空，但是如果是 kerberos 环境，则通常该配置项有值，需要进行配置，例如：`dfs.data.transfer.protection=authentication,privacy`，指定数据传输保护级别为 `authentication` 和 `privacy`。

    * 基于 Hadoop HA（高可用）的逻辑命名服务访问集群格式为：`LOCATION = hdfs://nameserviceID/PATH`，其中 `nameserviceID` 指的是 HDFS 的是 Hadoop HA 的逻辑命名服务 ID，`PATH` 指文件路径。

      <main id="notice" type='explain'>
        <h4>说明</h4>
        <p>请确保客户端 OBServer 侧的配置包含 HA 集群的 <code>nameservice</code> 定义及故障转移策略。</p>
      </main>

      * 带 kerberos 认证的格式为：`LOCATION = 'hdfs://nameserviceID/PATH?principal=xxx&keytab=xxx&krb5conf=xxx&configs=dfs.data.transfer.protection=${string}#dfs.nameservices=${nameservice id}#dfs.ha.namenodes.${nameservice id}=${namenode1}, ${namenode2}#dfs.namenode.rpc-address.${nameservice id}.${namenode1}=${namenode 1 address}#dfs.namenode.rpc-address.${nameservice id}.${namenode2}=${namenode 2 address}#dfs.ha.automatic-failover.enabled.${nameservice id}=true#dfs.client.failover.proxy.provider.${nameservice id}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'`，其中：

        * `principal`：指登录认证用户，设置为非主节点 NN 的 `pricipal`。
        * `keytab` 和 `krb5conf`：与单节点 NN 设置一样。
        * `configs`：指定额外的 HDFS 配置项，需要设置多配置项，仅和 HA 配置项和安全配置项相关：

          * `dfs.data.transfer.protection=${string}`：对齐集群的 `dfs.data.transfer.protection` 的配置。
          * `dfs.nameservices=${nameservice id}`：指明当前 HA 集群的 `namesevice`（别名）。
          * `dfs.ha.namenodes.${nameservice id}=${namenode1}, ${namenode2}`：指明 HA 集群的 namenode 后备 ID 列表。
          * `dfs.namenode.rpc-address.${nameservice id}.${namenode1}=${namenode 1 address}`：设置说明 `namenode1` 具体 namenode，方便客户端路由。
          * `dfs.namenode.rpc-address.${nameservice id}.${namenode2}=${namenode 2 address}`：设置说明 `namenode2` 具体 namenode，方便客户端路由。
          * `dfs.ha.automatic-failover.enabled.${nameservice id}=true`：让 HA 集群获取相关请求之后，自动获取可用 namenode 进行响应服务。
          * `dfs.client.failover.proxy.provider.${nameservice id}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider`：指示 HA 集群进行主备切换的逻辑工具类，也可自定义打包上传 HA 集群自己需要的逻辑等。

      <main id="notice" type='notice'>
        <h4>注意</h4>
        <p>HA 部分配置项是和 <code>namespace</code> 绑定，例如如下示例三的 <code>mycluster</code>, 注意相关配置项结合设置。</p>
      </main>

### 定义 FORMAT

* `FORMAT = ( TYPE = 'CSV'... )` 用于指定外部文件的格式为 CSV 类型。有以下参数：
  * `TYPE`：指定外部文件的类型。
  * `LINE_DELIMITER`：指定 CSV 文件的行分隔符。默认值为 `LINE_DELIMITER='\n'`
  * `FIELD_DELIMITER`：指定 CSV 文件的列分隔符。默认值为 `FIELD_DELIMITER='\t'`。
  * `ESCAPE`：指定 CSV 文件的转义符号，只能为 1 个字节。默认值为 `ESCAPE ='\'`。
  * `FIELD_OPTIONALLY_ENCLOSED_BY`：指定 CSV 文件中包裹字段值的符号。默认值为空。

    <main id="notice" type='notice'>
      <h4>注意</h4>
      <p>当外表数据文件中包含 <code>NULL</code> 值（非字符串 <b>NULL</b>，即不是 <b>"NULL"</b>）时，必须显式配置 <code>FIELD_OPTIONALLY_ENCLOSED_BY</code> 参数，且该参数值不可为空。</p>
    </main>

  * `ENCODING`：指定文件的字符集编码格式，当前 Oracle 模式支持的所有字符集请参见 [字符集和字符序](../../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/300.basic-elements-of-oracle-mode/1000.character-set-and-collation-of-oracle-mode.md)。如果不指定，默认值为 UTF8MB4。
  * `NULL_IF`：指定被当作 `NULL` 处理的字符串。默认值为空。
  * `SKIP_HEADER`：跳过文件头，并指定跳过的行数。
  * `SKIP_BLANK_LINES`：指定是否跳过空白行。默认值为 `FALSE`，表示不跳过空白的行。
  * `TRIM_SPACE`：指定是否删除文件中字段的头部和尾部空格。默认值为 `FALSE`，表示不删除文件中字段头尾的空格。
  * `EMPTY_FIELD_AS_NULL`：指定是否将空字符串当作 `NULL` 处理。默认值为 `FALSE`，表示不将空字符串当做 `NULL` 处理。
* `FORMAT = ( TYPE = 'PARQUET'... )` 用于指定外部文件的格式为 PARQUET 类型。
* `FORMAT = ( TYPE = 'ORC'... )` 用于指定外部文件的格式为 ORC 类型。

### （可选）定义 PATTERN

`PATTERN` 选项用来指定一个正则模式串，用于过滤 `LOCATION` 目录下的文件。对于每个 `LOCATION` 目录下的文件路径，如果能够匹配该模式串，外表会访问这个文件，否则外表会跳过这个文件。如果不指定该参数，则默认可以访问 `LOCATION` 目录下的所有文件。外表会将`LOCATION` 指定路径下满足 `PATTERN` 的文件列表保存在数据库系统表中，外表扫描时会根据这个列表来访问外部的文件。

### （可选）定义外表分区

#### 自动定义外表分区

外表会根据分区键定义的表达式，计算并添加分区。您在查询时，可以指定分区键的值或者范围。此时会进行分区裁剪，外表只会读取该分区下的文件。

#### 手动定义外表分区

当您需要自己手动添加和删除分区，而不是让外表自动管理分区时，需要指定 `PARTITION_TYPE = USER_SPECIFIED` 字段。

## 示例一

<main id="notice" type='notice'>
  <h4>注意</h4>
  <p>示例中涉及 IP 的命令做了脱敏处理，在验证时应根据自己机器真实 IP 填写。</p>
</main>

以下将以外部文件的位置在本地和在 OceanBase 数据库 Oracle 模式中创建外表为例，步骤如下：

1. 准备外部文件。

    执行以下命令，在要登录 OBServer 节点所在机器的 `/home/admin/external_csv` 目录下，创建文件 `test_tbl1.csv`。

    ```shell
    [admin@xxx /home/admin/external_csv]# vi test_tbl1.csv
    ```

    文件的内容如下：

    ```shell
    1,'Emma'
    2,'William'
    3,'Olivia'
    ```

2. 设置导入的文件路径。

    <main id="notice" type='notice'>
      <h4>注意</h4>
      <p>由于安全原因，设置系统变量 <code>secure_file_priv</code> 时，只能通过本地 Unix Socket 连接数据库执行修改该全局变量的 SQL 语句。更多信息，请参见 <a href="../../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>。</p>
    </main>

    1. 执行以下命令，登录到 OBServer 节点所在的机器。

        ```shell
        ssh admin@10.10.10.1
        ```

    2. 执行以下命令，通过本地 Unix Socket 连接方式连接租户 `oracle001`。

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -usys@oracle001 -p******
        ```

    3. 执行以下 SQL 命令，设置导入路径为 `/home/admin/external_csv`。

        ```sql
        SET GLOBAL secure_file_priv = "/home/admin/external_csv";
        ```

3. 重新连接租户 `oracle001`。

    示例如下：

    ```shell
    obclient -h10.10.10.1 -P2881 -usys@oracle001 -p****** -A
    ```

4. 执行以下 SQL 命令，创建外表 `test_tbl1_csv`。

    ```sql
    CREATE EXTERNAL TABLE test_tbl1_csv ( 
        id INT, 
        name VARCHAR(50)
        )
        LOCATION = '/home/admin/external_csv'
        FORMAT = (
          TYPE = 'CSV'
          FIELD_DELIMITER = ','
          FIELD_OPTIONALLY_ENCLOSED_BY =''''
          )
        PATTERN = 'test_tbl1.csv';
    ```

5. 执行以下 SQL 命令，查看外表 `test_tbl1_csv` 数据。

    ```sql
    SELECT * FROM test_tbl1_csv;
    ```

    返回结果如下：

    ```shell
    +------+---------+
    | ID   | NAME    |
    +------+---------+
    |    1 | Emma    |
    |    2 | William |
    |    3 | Olivia  |
    +------+---------+
    3 rows in set
    ```

## 示例二

创建 HDFS 外表，需要 OceanBase 数据库在具有 JAVA SDK 的环境当中使用。关于部署 JAVA SDK 环境的详细介绍信息，参见 [部署 OceanBase 数据库 JAVA SDK 环境](../../../400.deploy/300.deploy-oceanbase-enterprise-edition/500.deploy-the-ob-java-sdk-environment.md)。

HDFS 外表创建示例

**带 kerberos：**

```shell
CREATE EXTERNAL TABLE ext_data(ID NUMBER(32), NAME VARCHAR2(30),SCORE NUMBER(32))
FORMAT = (
TYPE = 'CSV'
FIELD_DELIMITER = ','
FIELD_OPTIONALLY_ENCLOSED_BY ='"'
)
LOCATION = 'hdfs://localhost:8020/user?principal=principal_str&keytab=/path/to/keytab&krb5conf=/path/to/krb5conf_file&configs=xxx=xxx#xxx=xxx'
PATTERN = 'data.csv';
```

其中：

* `principal`：指定登录认证用户。
* `keytab`:指定用户认证的密钥文件路径。
* `krb5conf`:指定用户使用 kerberos 环境的描述文件路径。
* `configs`: 指定额外的 HDFS 配置项，默认为空，但是如果是 kerberos 环境，则通常该配置项有值，需要进行配置，例如：`dfs.data.transfer.protection=authentication,privacy`，指定数据传输保护级别为 `authentication` 和 `privacy`。

**不带 kerberos：**

```shell
CREATE EXTERNAL TABLE ext_data(ID NUMBER(32), NAME VARCHAR2(30),SCORE NUMBER(32))
FORMAT = (
  TYPE = 'CSV'
  FIELD_DELIMITER = ','
  FIELD_OPTIONALLY_ENCLOSED_BY ='"'
)
LOCATION = 'hdfs://localhost:8020/user'
PATTERN = 'test_tbl1.csv';
```

## 相关文档

更多有关查看和更新外表可访问文件的信息，请参见 [管理外部文件](../../../700.reference/300.database-object-management/200.manage-object-of-oracle-mode/100.manage-tables-of-oracle-mode/1000.manage-external-tables-of-oracle-mode/300.manage-external-files-of-oracle-mode.md)。
