# 基于 OceanBase 构建智能问答机器人

## 背景信息

在当今信息爆炸的时代，用户常需要从海量数据中迅速搜索所需信息。例如在线文献数据库、电商平台产品目录、以及不断增长的多媒体内容库，都需要高效的搜索系统来快速定位到用户感兴趣的内容。随着数据量不断激增，传统的基于关键字的搜索方法已经无法满足用户对于搜索精度和速度的需求，向量搜索技术应运而生。它通过将文本、图片、音频等不同类型的数据编码为数学上的向量，并在向量空间中进行搜索。这种方法允许系统捕捉数据的深层次语义信息，从而提供更为准确和高效的搜索结果。

本文通过 OceanBase 的向量搜索能力构建文档智能助手。

## 文档智能助手架构

文档智能助手将文档以向量的形式批量存储在 OceanBase 数据库内。用户通过 UI 界面提问，程序使用 BGE-M3 模型将提问内容嵌入成为向量并在数据库中搜索相似向量，得到相似向量对应的文档内容后，应用将它们会同用户提问一起发送给 LLM，LLM 会根据提供的文档生成更加准确的回答。

![5](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/observer/V4.3.5/vector_search/rag-flow.png)

## 前提条件

* 您已部署 OceanBase V4.3.3 及以上版本的集群并且创建了 MySQL 模式租户。更多有关部署 OceanBase 集群的信息，请参见 [部署概述](../400.deploy/100.deploy-overview.md)

* 您所创建的 MySQL 模式租户需要拥有插入及查询的权限。更多有关权限设置的信息，请参见 [直接授予权限](../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/200.permission-of-mysql-mode/200.authority-of-mysql-mode.md)。

* 您已创建数据库。更多有关创建数据库的信息，请参见 [创建数据库](../300.develop/100.application-development-of-mysql-mode/300.database-object-planning-of-mysql-mode/100.create-database-of-mysql-mode-in-develop.md)。


* 数据库已开启向量搜索功能。更多关于向量搜索功能的信息，请参见 [使用 SQL 快速进行向量搜索](../640.ob-vector-search/120.ob-vector-search-quick-start/100.ob-vector-search-sql-quick-start.md)。

    ```shell
    obclient> ALTER SYSTEM SET ob_vector_memory_limit_percentage = 30;
    ```

* 安装 Python 3.11 及以上版本。

* 安装 Poetry：

    ```shell
    python3 -m ensurepip
    python3 -m pip install poetry
    ```

## 步骤一：注册 LLM 平台账号

注册[阿里云百炼](https://bailian.console.aliyun.com/)账号，开通模型服务并获取 API 密钥。

<main id="notice" type='warning'>
  <h4>注意</h4>
  <p>开通阿里云百炼大模型服务需要您跳转至第三方平台完成。此操作将遵循第三方平台的收费规则，并可能产生相应费用。请在继续前，访问其官网或查阅相关文档，确认并接受其收费标准。如不同意，请勿继续操作。</p>
</main>

<main id="notice" type='notice'>
    <h4>注意</h4>
    <p>本教程以通义千问 LLM 为例来介绍问答机器人的搭建，您也可以选择使用其他 LLM 进行搭建，选用其他 LLM 需要更新 <code>.env</code> 文件中的 <code>API_KEY</code>、<code>LLM_BASE_URL</code> 和 <code>LLM_MODEL</code>。</p>
</main>

![点击开通模型服务](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/activate-models.png)

![确认开通模型服务](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/confirm-to-activate-models.png)

![阿里云百炼](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/AI/%E7%99%BE%E7%82%BC1.jpg)

![获取阿里云百炼 API Key](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/AI/%E7%99%BE%E7%82%BC3.1.png)

## 步骤二：构建你的 AI 助手

### 克隆代码仓库

```shell
git clone https://gitee.com/oceanbase-devhub/ai-workshop-2024
cd ai-workshop-2024
```

### 安装依赖

```shell
poetry install
```

### 设置环境变量

```shell
cp .env.example .env
# 如果您使用通义千问提供的 LLM 能力，则需要把 API_KEY 和 OPENAI_EMBEDDING_API_KEY 更新为您从阿里云百炼控制台获取的 API KEY 值，并将 DB_ 开头的变量更新为您的数据库连接信息，然后保存文件。
vi .env
```

### 连接数据库

您可使用我们准备好的脚本来尝试连接数据库，以确保数据库相关的环境变量设置成功：

```bash
bash utils/connect_db.sh
# 如果顺利进入 MySQL 连接当中，则验证了环境变量设置成功
```

### 准备文档语料

在该步骤中，我们将克隆 OceanBase 相关组件的开源文档仓库并处理它们，生成文档的向量数据和其他结构化数据后将数据插入到 OceanBase 数据库。

1. 克隆并处理文档仓库

    <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>此步骤需下载和处理大量 OceanBase 文档，会花费较长时间。</p>
    </main>

   ```shell
   git clone --single-branch --branch V4.3.3 https://github.com/oceanbase/oceanbase-doc.git doc_repos/oceanbase-doc
   # 如果您访问 Github 仓库速度较慢，可以使用以下命令克隆 Gitee 的镜像版本
   git clone --single-branch --branch V4.3.4 https://gitee.com/oceanbase-devhub/oceanbase-doc.git doc_repos/oceanbase-doc
   ```

2. 文档格式标准化

   因为 OceanBase 的开源文档中有些文件使用 `====` 和 `----` 来表示一级标题和二级标题，我们在这一步将其转化为标准的 `#` 和 `##` 表示。

   ```shell
   # 将标题转换为标准 Markdown 格式
   poetry run python convert_headings.py \
     doc_repos/oceanbase-doc/zh-CN \

3. 将文档转换为向量并插入 OceanBase 数据库

   我们提供了 `embed_docs.py` 脚本，通过指定文档目录和对应的组件后，该脚本就会遍历目录中的所有 markdown 格式的文档，将长文档进行切片后使用嵌入模型转换为向量，并最终将文档切片的内容、嵌入的向量和切片的元信息（JSON 格式，包含文档标题、相对路径、组件名称、切片标题、级联标题）一同插入到 OceanBase 的同一张表中，作为预备数据待查。

   为了节省时间，我们只处理 OceanBase 众多文档中与向量搜索有关的几篇文档，打开聊天界面之后，您针对 OceanBase 的向量搜索功能进行的提问将得到较为准确的回答。

   ```bash
   # 生成文档向量和元数据
   poetry run python embed_docs.py --doc_base doc_repos/oceanbase-doc/zh-CN/640.ob-vector-search
   ```

### 启动 UI 聊天界面

执行以下命令启动聊天界面：

```bash
poetry run streamlit run --server.runOnSave false chat_ui.py
```

访问终端中显示的 URL 来打开聊天机器人应用界面。

```bash
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://172.xxx.xxx.xxx:8501
  External URL: http://xxx.xxx.xxx.xxx:8501 # 这是您可以从浏览器访问的 URL
```

## 应用展示

<main id="notice" type='notice'>
  <h4>注意</h4>
  <p>由于本应用基于 OceanBase 文档语料构建，请就 OceanBase 相关问题向您的助手提问。</p>
</main>

![chatbot-ui](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/rag_pic.png)

## 在线 Demo 体验

除自己构建智能问答机器人应用外，您还可以访问[文档小助手](https://www.oceanbase.com/demo/chatbot)登录体验在线 Demo 应用，Demo 界面的官网入口为**资源与服务-学习-在线体验-在线 Demo**。以下为界面展示：

![tourism-assistant-demo](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/AI/raglivedemo%E9%A1%B5%E9%9D%A2%E5%B1%95%E7%A4%BA%E5%9B%BE.jpg)
