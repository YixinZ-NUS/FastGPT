|description||
|---|---|
|keywords||
|dir-name||
|dir-name-en||
|tenant-type||

# Export data using the OUTFILE statement

The `SELECT INTO OUTFILE` statement is a common method for exporting data. It allows you to specify the fields to be exported, which is useful in scenarios where you don't want to export the primary key fields. When used in conjunction with the `LOAD DATA INFILE` statement for importing data, it provides a convenient way to import and export data.

## Background information

OceanBase Database is compatible with this syntax.

|    Mode   | Recommended OceanBase Database version | Recommended client |
|-----------|-----------------------|-----------------------|
| MySQL mode  | V2.2.40 and later           | MySQL Client or OBClient |
| Oracle mode | V2.2.40 and later           | OBClient              |

  <main id="notice" type='notice'>
    <h4>Notice</h4>
    <p>The client must be directly connected to the OceanBase Database instance for import and export operations. </p>
  </main>

## Privilege requirements

* To execute the `SELECT INTO` statement in a MySQL tenant, you must have the `FILE` privilege and the `SELECT` privilege on the table. You can use the following command to grant the `FILE` privilege to a user:

   ```sql
    GRANT FILE ON *.* TO user_name;
   ```

   In the statement, `user_name` is the username of the account that executes the `SELECT INTO` statement. For more information about privileges in OceanBase Database in MySQL mode, see [Privilege types in MySQL-compatible mode](../../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/200.permission-of-mysql-mode/100.permission-classification-of-mysql.md).

* To execute the `SELECT INTO` statement in an Oracle tenant, you must have the `SELECT` privilege on the table. For more information about OceanBase Database privileges, see [Privilege types in Oracle-compatible mode](../../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/300.permission-of-oracle-mode/000.permission-classification-of-oracle-mode.md).

## Syntax

```sql
SELECT [/*+parallel(N)*/] column_list_option
INTO {OUTFILE 'file_name' [PARTITION BY part_expr] [{CHARSET | CHARACTER SET} charset_name] [field_opt] [line_opt] [file_opt]
     | OUTFILE 'file_name' [PARTITION BY part_expr] [FORMAT = (external_file_format_list)] [file_opt]
     | DUMPFILE 'file_name'
     | into_var_list}
FROM table_name_list
[WHERE where_conditions]
[GROUP BY group_by_list [HAVING having_search_conditions]]
[ORDER BY order_expression_list];

column_list_option:
    column_name [, column_name ...]

field_opt:
    {COLUMNS | FIELDS} field_term_list

field_term_list:
  field_term [, field_term ...]

field_term:
    {[OPTIONALLY] ENCLOSED | TERMINATED | ESCAPED} BY string

line_opt:
    LINES line_term_list

line_term_list:
    line_term [, line_term ...]

line_term:
    {STARTING | TERMINATED} BY string

file_opt:
    file_option [, file_option ...]

file_option:
    SINGLE [=] {TRUE | FALSE}
    | MAX_FILE_SIZE [=] {int | string}
    | BUFFER_SIZE [=] {int | string}

external_file_format_list:
    type_csv_option
    | type_parquet_option
    | type_orc_option

type_csv_option:
    TYPE = 'CSV'
    LINE_DELIMITER = '<string>' | <expr>
    FIELD_DELIMITER = '<string>' | <expr>
    ESCAPE = '<character>' | <expr>
    FIELD_OPTIONALLY_ENCLOSED_BY = '<character>' | <expr>
    FIELD_ENCLOSED_BY = '<character>' | <expr>
    ENCODING = 'charset'
    COMPRESSION = [NONE, GZIP, DEFLATE, ZSTD] | '<string>'
    FILE_EXTENSION = ['<string>']

type_parquet_option:
    TYPE = 'PARQUET',
    COMPRESSION = '<string>'
    ROW_GROUP_SIZE = '<string>' | <int>

type_orc_option:
    TYPE = 'ORC'
    COMPRESSION = '<string>'
    COMPRESSION_BLOCK_SIZE = '<string>' | <int>
    STRIPE_SIZE = '<string>' | <int>
    ROW_INDEX_STRIDE = <int>
```

## Parameters

| Parameter | Description |
|------------------------|-----------|
| parallel(N)            | Optional. Specifies the degree of parallelism for executing the statement. |
| column_list_option     | Specifies the column options. You can use `*` to select all columns. </br>`column_name`: the name of the column. For more information about column options in queries, see [SIMPLE SELECT](../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/900.sql-statement-of-oracle-mode/200.dml-of-oracle-mode/500.select-of-oracle-mode/100.simple-select-of-oracle-mode.md). |
| file_name              | The path and name of the exported file. For more information, see [file_name](#file_name). |
| PARTITION BY part_expr | <main id="notice" type='explain'><h4>Note</h4><p>For OceanBase Database V4.3.2, the PARTITION BY clause has been added in V4.3.2 BP1 to control the partitioning method for exported data.</p></main> Optional. Specifies the partitioning method for exported data. The value of `part_expr` serves as a part of the export path. The system calculates the value of `part_expr` for each row of data. Rows of data for which the value of `part_expr` is the same belong to the same partition and are exported to the same directory. <main id="notice" type='notice'><h4>Notice</h4><p><ul><li>When data is exported by partition, <code>SINGLE = FALSE</code> must be specified, that is, multiple files are allowed. </li><li>At present, exporting data by partition is supported only for import to Alibaba Cloud OSS. </li></ul></p></main> |
| FORMAT = (external_file_format_list)| Optional. Specifies the file format for the statement in the FORMAT clause. Use TYPE to specify the file format. TYPE cannot be left empty. For more information, see [external_file_format_list](#external_file_format_list). |
| CHARSET \| CHARACTER SET charset_name | Optional. Specifies the character set for exporting data to an external file. `charset_name` indicates the name of the character set. |
| field_opt              | Optional. Specifies the field options for exporting data. You can use the `FIELDS` or `COLUMNS` clause to specify field options. For more information, see [field_term](#field_term). |
| line_opt               | Optional. Specifies the start and end characters of each line in the exported file. You can set the start and end characters of each line in the output file by using the `LINES` clause. For more information, see [line_term](#line_term). |
| file_opt               | Optional. Specifies whether to export data to multiple files and the size of each file when data is exported to multiple files. For more information, see [file_option](#file_option). |
| FROM table_name_list   | Specifies the objects from which to select data. |
| WHERE where_conditions | Optional. Specifies the filter conditions. Only data that meets the conditions is returned in the query result. For more information about filters in queries, see [SIMPLE SELECT](../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/900.sql-statement-of-oracle-mode/200.dml-of-oracle-mode/500.select-of-oracle-mode/100.simple-select-of-oracle-mode.md). |
| GROUP BY group_by_list | Optional. Specifies the grouping columns. Generally, it is used in combination with aggregate functions. <main id="notice" type='explain'><h4>Note</h4><p>All columns that are not followed by aggregate functions in the columns specified after the <code>SELECT</code> clause must be specified after the <code>GROUP BY</code> clause. </p></main> |
| HAVING having_search_conditions | Optional. Specifies the filter conditions for grouped data. The `HAVING` clause is similar to the `WHERE` clause, but the `HAVING` clause can use cumulative functions such as `SUM` and `AVG`. |
| ORDER BY order_expression_list  | Optional. Specifies the one or more columns to sort the result set in ascending (`ASC`) or descending (`DESC`) order. The default order is ascending. <ul><li>`ASC`: indicates ascending order. </li><li>`DESC`: indicates descending order. </li></ul>|

### file_name

The `file_name` parameter has the following format:

* When the export file is stored on an OBServer node, specify the path and file name in the format of `\$PATH/\$FILENAME`. The parameters are described as follows:

  * `$PATH`: specifies the path to save the exported file, which is the path of the export file on the OBServer node.
  * `\$FILENAME`: the name of the file to be exported. When `SINGLE = FALSE`, it specifies the prefix of the exported file. If you do not specify this parameter, the system uses the default prefix `data`. The system automatically generates the suffix.

* When an exported file is saved to OSS, the file path is in the `oss://\$PATH/\$FILENAME/?host=\$HOST&access_id=\$ACCESS_ID&access_key=\$ACCESSKEY` format, where:

  * `\$PATH`: the path of the bucket to which the exported file is saved.
  * `\$FILENAME`: the name of the exported file.
  * `\$HOST`: the address of the OSS endpoint.
  * `\$ACCESS_ID`: the Access ID of the ApsaraDB for OSS account.
  * `\$ACCESSKEY`: the Access Key of the ApsaraDB for OSS account.

    <main id="notice" type='explain'>
      <h4>Note</h4>
      <p><ul><li>For OceanBase Database V4.3.5, <code>SELECT INTO</code> has been adapted to support S3 and S3 protocol-based object storage as the destination for data export starting from V4.3.5 BP2.</li><li>Due to file size limitations in Alibaba Cloud OSS, files larger than 5 GB will be split into multiple files, with each file being smaller than 5 GB when exported to OSS.</li></ul></p>
    </main>

### field_term

* `[OPTIONALLY] ENCLOSED BY string`: Specifies the symbol that encloses field values. By default, there is no enclosing symbol. For example, `ENCLOSED BY '"'` means that character values are enclosed in double quotes. If the `OPTIONALLY` keyword is used, the specified enclosing character is applied only to string-type values.  
* `TERMINATED BY string`: Specifies the delimiter between field values. For example, `TERMINATED BY ','` specifies a comma as the delimiter between two field values.  
* `ESCAPED BY string`: Specifies the escape character for handling special characters or parsing specially formatted data. The default escape character is a backslash (`\`).  

### line_term

* `TERMINATED BY string`: Specifies the end character for each line. By default, a newline character is used. For example, `... LINES TERMINATED BY '\n' ...` indicates that each line ends with a newline character.

### file_option

* `SINGLE [=] {TRUE | FALSE}`: specifies whether to export data to a single file or multiple files.

  * `SINGLE [=] TRUE`: specifies to export data to a single file. This is the default value.
  * `SINGLE [=] FALSE`: specifies to export data to multiple files.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>When the degree of parallelism is greater than 1 and <code>SINGLE = FALSE</code>, data can be exported to multiple files to achieve parallel reading, parallel writing, and improved export efficiency. </p>
    </main>

* `MAX_FILE_SIZE [=] {int | string}`: specifies the maximum size of a file when data is exported to multiple files. This parameter is effective only when `SINGLE = FALSE`.

* `BUFFER_SIZE [=] {int | string}`: specifies the size of memory applied for each thread for each partition when data is exported. This parameter is not effective for non-partitioned tables. The default value is 1 MB.

  <main id="notice" type='explain'>
    <h4>Note</h4>
    <p><ul><li><code>BUFFER_SIZE</code> is used for export performance tuning. If sufficient memory is available on the server and you want to improve the export efficiency, you can set a large value (for example, 4 MB). If the memory is insufficient, you can set a small value (for example, 4 KB). If you set it to 0, all partitions of a thread share a public memory. </li><li>Starting from OceanBase Database V4.3.2 BP1, the <code>BUFFER_SIZE</code> parameter is supported. </li></ul></p>
  </main>

### external_file_format_list

* When **TYPE = 'CSV'**, the fields included are as follows:

  * `LINE_DELIMITER`: specifies the line delimiter of the CSV file. The default value is `'\n'`.
  * `FIELD_DELIMITER`: specifies the field delimiter of the CSV file. The default value is `'\t'`.
  * `ESCAPE`: specifies the escape character of the CSV file. The value must be 1 byte in length. The default value is `'\'`.
  * `FIELD_OPTIONALLY_ENCLOSED_BY`: specifies the characters that enclose the field values in the CSV file. This parameter is optional. The default value is an empty string. This option allows you to add enclosing characters only to specific types of fields, such as CHAR, VARCHAR, TEXT, and JSON.
  * `FIELD_ENCLOSED_BY`: specifies the characters that enclose the field values in the CSV file. This parameter is optional. The default value is an empty string, which specifies not to add enclosing characters. This option adds enclosing characters to all types of fields.
  * `ENCODING`: specifies the character set encoding format of the file. If this parameter is not specified, the default value `UTF8MB4` takes effect.
  * `COMPRESSION`: specifies the compression format of the file. This parameter is optional. The supported compression formats are NONE, GZIP, DEFLATE, and ZSTD.
    * `GZIP`/`DEFLATE`: specifies the GZIP compression format.
    * `ZSTD`: specifies the ZSTD compression format.
    * `NONE`: specifies that the file is not compressed. This is the default value.
  * `FILE_EXTENSION`: specifies the user-defined file extension. This parameter is optional. It is supported only for multi-file export and applies only to CSV files. If this parameter is not specified, the file extension is determined by the file format. The default file extension for CSV files is `.csv`.

* When **TYPE = 'PARQUET'**, the following fields are included:

  * `COMPRESSION`: specifies the compression format of the PARQUET file. The default value is `.parquet`. The supported compression formats are `UNCOMPRESSED` (which specifies that the file is not compressed), `SNAPPY`, `GZIP`, `BROTLI`, `ZSTD`, `LZ4`, and `LZ4_HADOOP`. If this parameter is not specified, the default value `UNCOMPRESSED` takes effect.
  * `COMPRESSION`: specifies the compression format of the ORC file. The default value is `.orc`. The supported compression formats are `UNCOMPRESSED` (which specifies that the file is not compressed), `SNAPPY`, `ZLIB`, `LZ4`, and `ZSTD`. If this parameter is not specified, the default value `UNCOMPRESSED` takes effect.

* `COMPRESSION_BLOCK_SIZE`: specifies the size of the block into which the data is compressed, in bytes. You can specify a numeric value or a string in the format of `'64KB'`. If this parameter is not specified, the default value `256KB` takes effect. We recommend that you use the default value.

  * `STRIPE_SIZE`: specifies the size of a stripe in the ORC file, in bytes. You can specify a numeric value or a string in the format of `'64MB'`. If this parameter is not specified, the default value `64MB` takes effect. We recommend that you use the default value.

## Considerations

* If multiple export tasks are exporting data to the same path at the same time, errors may occur and only a part of the data may be exported. You can avoid this issue by properly setting the export path. For example:

  ```shell
  SELECT /*+parallel(2)*/ * INTO OUTFILE 'test/data' SINGLE = FALSE FROM t1;
  ```

  ```shell
  SELECT /*+parallel(2)*/ * INTO OUTFILE 'test/data' SINGLE = FALSE FROM t2;
  ```

  If the export files have the same name, errors may occur. We recommend that you set the export path to <code>test/data1</code> and <code>test/data2</code>.

* If <code>SINGLE = FALSE</code> and the export fails because the file already exists, you can delete all files in the export directory that have the same prefix as the export target, or delete the export directory and recreate it, and then re-export the data. For example

  ```shell
  SELECT /*+parallel(2)*/ * INTO OUTFILE 'test/data' SINGLE = FALSE FROM t1;
  ```

  After the failure, you can delete all files with the <code>data</code> prefix in the <code>test</code> directory, or directly delete the <code>test</code> directory and recreate it, and then try to export the data again.

* Compression applies to data blocks in Parquet and ORC files, not to the entire files. Therefore, only the CSV format supports compression suffixes.

* When you export a compressed CSV file, the file names are different whether you export single files or multiple files.

  * If you export multiple files (`SINGLE = FALSE`), and a compression algorithm is specified, use the suffix corresponding to the compression algorithm. The suffix is placed at the end of the file name. For example, if the file name of the exported file is `data_1_0_1` and the specified compression algorithm is `gzip`, the file name is `data_1_0_1.gz`.

  * If you export a single file (`SINGLE = TRUE`), the output file name is the same as the specified file name. That is, if a compression suffix is specified, it is also included in the output file name. If no compression suffix is specified, the suffix is not output.

* The logical order of the `FILE_EXTENSION` field when you export a CSV file is as follows:

  * If you specify both the `COMPRESSION` and `FILE_EXTENSION` parameters, the suffix order is `.file_extension.compression`. For example, if the file name of the exported file is `data_0_0_1`, the `FILE_EXTENSION` parameter is set to `xls`, and the `COMPRESSION` parameter is set to `gzip`, the file name is `data_0_0_1.xls.gz` when multiple files are exported.

  * Regardless of whether the value of the `FILE_EXTENSION` parameter starts with a `.`, the output file name contains only one `. `. For example, if the file name of the exported file is `data` and the `FILE_EXTENSION` parameter is set to `xls` or `.xls`, the file name is `data.xls`.

## Example

### Export data to a local file

**Example 1: Use the `SELECT INTO OUTFILE` statement to export a CSV file**

:::tab
tab MySQL mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `mysql001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@mysql001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [test]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data.

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.csv`, the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/test_tbl1.csv'
                        FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/'
                        FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                        SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/dd2024'
                        FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                        SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.csv.gz  dd2024_0.csv.gz  test_tbl1.csv 
   ```

   In this example, `test_tbl1.csv` is the file name exported by the serial single-file export example; `data_0.csv.gz` is the file name exported by the parallel multiple-file export example without a specified file name, with the compression algorithm set to `gzip`; and `dd2024_0.csv.gz` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`, with the compression algorithm set to `gzip`.

tab Oracle mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `oracle001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@oracle001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [SYS]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data.

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.csv`, the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/test_tbl1.csv'
                      FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/'
                      FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the character set as `utf8mb4`, and the compression format as `gzip`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/dd2024'
                      FORMAT = (TYPE = 'CSV', FIELD_DELIMITER = ',', ENCODING = 'utf8mb4', COMPRESSION = gzip)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.csv.gz  dd2024_0.csv.gz  test_tbl1.csv 
   ```

   In this example, `test_tbl1.csv` is the file name exported by the serial single-file export example; `data_0.csv.gz` is the file name exported by the parallel multiple-file export example without a specified file name, with the compression algorithm set to `gzip`; and `dd2024_0.csv.gz` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`, with the compression algorithm set to `gzip`.

:::

**Example 2: Use the `SELECT INTO OUTFILE` statement to export a PARQUET file**

:::tab
tab MySQL mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `mysql001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@mysql001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [test]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data. You can use a mapping table to convert the various data types in MySQL mode to the data types supported by PARQUET. For more information about the data types supported by the PARQUET format, see [Data type mapping table](../../700.reference/300.database-object-management/100.manage-object-of-mysql-mode/200.manage-tables-of-mysql-mode/1000.manage-external-tables-of-mysql-mode/400.data-type-mapping-of-mysql-mode.md).

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.parquet`, the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/test_tbl1.parquet'
                        FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/'
                        FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                        SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                        INTO OUTFILE '/home/admin/test_data/dd2024'
                        FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                        SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                       FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.parquet  dd2024_0.parquet  test_tbl1.parquet
   ```

   In this example, `test_tbl1.parquet` is the file name exported by the serial single-file export example; `data_0.parquet` is the file name exported by the parallel multiple-file export example without a specified file name; and `dd2024_0.parquet` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`.

tab Oracle mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `oracle001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@oracle001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [SYS]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data. You can use a mapping table to convert the various data types in Oracle mode to the data types supported by PARQUET. For more information about the data types supported by the PARQUET format, see [Data type mapping table](../../700.reference/300.database-object-management/200.manage-object-of-oracle-mode/100.manage-tables-of-oracle-mode/1000.manage-external-tables-of-oracle-mode/400.data-type-mapping-of-oracle-mode.md).

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.parquet`, the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                     INTO OUTFILE '/home/admin/test_data/test_tbl1.parquet'
                     FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/'
                      FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the compression format as `SNAPPY`, and the size of a row group as `128 MB`.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/dd2024'
                      FORMAT = (TYPE = 'PARQUET'  COMPRESSION = 'SNAPPY' ROW_GROUP_SIZE = '128MB')
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.parquet  dd2024_0.parquet  test_tbl1.parquet
   ```

   In this example, `test_tbl1.parquet` is the file name exported by the serial single-file export example; `data_0.parquet` is the file name exported by the parallel multiple-file export example without a specified file name; and `dd2024_0.parquet` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`.

:::

**Example 3: Use the `SELECT INTO OUTFILE` statement to export an ORC file**

:::tab
tab MySQL mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `mysql001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@mysql001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [test]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data. You can use a mapping table to convert the various data types in MySQL mode to the data types supported by ORC. For more information about the data types supported by the ORC format, see [Data type mapping table](../../700.reference/300.database-object-management/100.manage-object-of-mysql-mode/200.manage-tables-of-mysql-mode/1000.manage-external-tables-of-mysql-mode/400.data-type-mapping-of-mysql-mode.md).

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.orc`, the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/test_tbl1.orc'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                     FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                     FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [test]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/dd2024'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                     FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.orc  dd2024_0.orc  test_tbl1.orc
   ```

   In this example, `test_tbl1.orc` is the file name exported by the serial single-file export example; `data_0.orc` is the file name exported by the parallel multiple-file export example without a specified file name; and `dd2024_0.orc` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`.

tab Oracle mode

1. Log in to the server where the OBServer node to connect to resides.

   Go to the server where the OBServer node to connect to resides.

      ```shell
      [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
      ```

2. Set the file path for importing data.

    Set the system variable `secure_file_priv` to specify the path where you can access files for importing or exporting.

    <main id="notice" type='notice'>
      <h4>Notice</h4>
      <p>For security reasons, when you set the system variable <code>secure_file_priv</code>, you can connect to the database only through a local Unix socket to execute the SQL statement that modifies the global variable. For more information, see <a href="../../700.reference/800.configuration-items-and-system-variables/200.system-variable/300.global-system-variable/12000.secure_file_priv-global.md">secure_file_priv</a>. </p>
    </main>

    1. Log in to the server where the OBServer node to connect to resides.

        ```shell
        [xxx@xxx /home/admin/test_data]# ssh admin@xxx.xxx.xxx.xxx
        ```

    2. Connect to the `oracle001` tenant through a local Unix socket.

        ```shell
        obclient -S /home/admin/oceanbase/run/sql.sock -uroot@oracle001 -p******
        ```

    3. Set the import path to `/home/admin/test_data`.

        ```shell
        obclient [SYS]> SET GLOBAL secure_file_priv = "/home/admin/test_data";
        Query OK, 0 rows affected
        ```

3. After reconnecting to the database, use the `SELECT INTO OUTFILE` statement to export data. You can use a mapping table to convert the various data types in Oracle mode to the data types supported by ORC. For more information about the data types supported by the ORC format, see [Data type mapping table](../../700.reference/300.database-object-management/200.manage-object-of-oracle-mode/100.manage-tables-of-oracle-mode/1000.manage-external-tables-of-oracle-mode/400.data-type-mapping-of-oracle-mode.md).

   * Export data to a single file in serial mode. Specify the file name as `test_tbl1.orc`, the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/test_tbl1.orc'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Do not specify the file name, and set the maximum size of each file to 4 MB. Specify the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

   * Write data to multiple files in parallel. Specify the file name prefix as `dd2024`, set the maximum size of each file to 4 MB, specify the compression format as `SNAPPY`, the size of a compressed block as `256 KB`, the size of a stripe as `64 MB`, and the index interval as 10,000 rows.

     ```shell
     obclient [SYS]>SELECT /*+parallel(2)*/ *
                      INTO OUTFILE '/home/admin/test_data/dd2024'
                      FORMAT = (TYPE = 'ORC' COMPRESSION = 'SNAPPY' COMPRESSION_BLOCK_SIZE = 262144  STRIPE_SIZE = 67108864  ROW_INDEX_STRIDE = 10000)
                      SINGLE = FALSE MAX_FILE_SIZE = '4MB'
                    FROM tbl1;
     ```

     The return result is as follows:

     ```shell
     Query OK, 9 rows affected
     ```

4. Log in to the server and check the exported file information in the `/home/admin/test_data` directory on the OBServer node.

   ```shell
   [xxx@xxx /home/admin/test_data]# ls
   ```

   The return result is as follows:

   ```shell
   data_0.orc  dd2024_0.orc  test_tbl1.orc
   ```

   In this example, `test_tbl1.orc` is the file name exported by the serial single-file export example; `data_0.orc` is the file name exported by the parallel multiple-file export example without a specified file name; and `dd2024_0.orc` is the file name exported by the parallel multiple-file export example with a specified file name prefix of `dd2024`.

:::

### Export data to OSS

You can execute the `SELECT INTO OUTFILE` statement to export data from the `test_tbl2` table to a specified OSS storage location based on partitions. The partitions are determined by the combination of the `col1` and `col2` columns. Rows with the same values in these two columns are considered to be in the same partition and exported to the same directory.

```shell
SELECT /*+parallel(3)*/ * FROM test_tbl2
  INTO OUTFILE 'oss://$DATA_FOLDER_NAME/?host=$OSS_HOST&access_id=$OSS_ACCESS_ID&access_key=$OSS_ACCESS_KEY'
    PARTITION BY CONCAT(col1,'/',col2)
    SINGLE = FALSE BUFFER_SIZE = '2MB';
```

The storage location is specified by the `$DATA_FOLDER_NAME` variable. You also need to provide the host address, access ID, and access key of the OSS service.

## More information

A file exported by using the `SELECT INTO OUTFILE` method can be imported by using the `LOAD DATA` statement. For more information, see [Import data by using the LOAD DATA statement](../700.migrate-data-from-csv-file-to-oceanbase-database/200.use-the-load-command-to-load-the-csv-data-file-to-the-oceanbase-database.md).